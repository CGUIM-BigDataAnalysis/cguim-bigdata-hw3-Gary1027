---
title: "長庚大學 大數據分析方法 作業三"
output: github_document
---

## 網站資料爬取
```{r}
#這是R Code Chunk
##第一次使用要先安裝 install.packages("rvest")
##read_html
##html_nodes
##html_text
library(xml2)
library(rvest) 
frame = data.frame(Title=character(),
                      Author=character(),
                      PushNum=character())
for(i in 4670:4675){
PTTURL<-paste0("https://www.ptt.cc/bbs/NBA/index",i,".html") 
PTTContent <- read_html(PTTURL)
post_title <- PTTContent %>% html_nodes(".title") %>% html_text() 
post_title <- gsub("\n",replacement="",post_title)
post_title <- gsub("\t",replacement="",post_title)
post_author<- PTTContent %>% html_nodes(".author") %>% html_text()
post_pushnum <- PTTContent %>% html_nodes(".nrec") %>% html_text()
PTTframe <- data.frame(Title = post_title, Author = post_author, PushNum = post_pushnum)
frame <- rbind(frame,PTTframe)
}
```

## 爬蟲結果呈現
```{r}
#這是R Code Chunk
knitr::kable(frame) ##請將iris取代為上個步驟中產生的爬蟲資料資料框
```

## 解釋爬蟲結果 
```{r}
str(frame)
table(frame$Author)
```
1 120篇
2Rambo最多

```{r}
#這是R Code Chunk
```

覺得爬蟲很有趣很方便，可以馬上找出熱門的文章。